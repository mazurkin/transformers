{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a991361-0445-4793-8711-5aacf68ec1da",
   "metadata": {},
   "source": [
    "https://medium.com/@hhpatil001/transformers-from-scratch-in-simple-python-part-i-b290760c1040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55dd60db-21d5-44c2-b6d7-7e51ea471b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "934cf721-e45c-4a22-b528-aa3e5bc92a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a12093dd-038c-46ae-9290-7b9963209f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18321618-9ba3-48e7-90ad-05c604d97364",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ea3c2c-a086-4093-beb1-f857c651a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I love data science.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0608097a-385c-4f9d-9830-b11a1fdc26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, add_special_tokens=False, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88a59c3a-7f97-4af0-8fe7-516a255500d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1045, 2293, 2951, 2671, 1012]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "305e336b-b7da-454e-9917-b3d230a3f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "090b43b7-7efd-420c-9c81-087c54466e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.44.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de3dd4f4-3f66-4739-a625-d755536a748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7be93f4-3f75-4321-8587-844b873f0f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da1fc42f-ac9e-4d8a-a887-6d37e6635c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_embeds = token_embeddings(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "198fc7da-38b1-40e1-9121-6442fab5a84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db2ef399-0243-48a5-9d94-7221732e6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = key = value = inputs_embeds\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value):\n",
    "    dim_k = query.size(-1)\n",
    "    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k) # torch.bmm is batch matrix - matrix multiplication. \n",
    "                                                                 # Basically a dot product.\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce7f7c2d-37d8-4a7b-b1f9-b0d00f10123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "    \n",
    "    def forward(self, hidden_state):\n",
    "        attn_outputs = scaled_dot_product_attention(self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n",
    "        return attn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d21911f8-69dc-43e6-8fc0-1ef93a455d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        self.heads = nn.ModuleList([AttentionHead(embed_dim, head_dim) for _ in range(num_heads)])\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "    def forward(self, hidden_state):\n",
    "        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n",
    "        x = self.output_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aa5dad7-442d-4f98-bea5-f4dd44c4b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn = MultiHeadAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df22ff79-3ceb-4ac7-91e7-8b69e28d971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output = multihead_attn(inputs_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbe18efa-b432-4c9f-b04a-b5fc75e153a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca3205af-fc62-41d3-a68d-386882792fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5be55ca-3022-4704-b479-9ca56bb10be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_forward = FeedForward(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9f22de6-bbc3-4f91-902a-7fa87aa3a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_outputs = feed_forward(attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7eaad280-f712-4119-bc51-c4d0270b9bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_outputs.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
